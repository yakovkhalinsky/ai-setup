x-common: &common
  restart: always
  env_file: .env

x-gpu: &gpu
  runtime: nvidia
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]

services:

  ollama:
    <<: [*gpu, *common]
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - "./ollama:/root/.ollama"

  open-webui:
    <<: [*common]
    image: ghcr.io/open-webui/open-webui:latest  
    ports:
      - "8080:8080"
    volumes:
      - ./open-webui:/app/backend/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      - ollama
      - comfyui

  comfyui:
    <<: [*gpu, *common]
    build:
      context: .
      dockerfile: comfyui/Dockerfile
    ports:
      - "8188:8188"
    volumes:
      - ./comfyui/models:/app/models

  db:
    <<: [*common]
    image: postgres:latest
    environment:
      - POSTGRES_USER
      - POSTGRES_PASSWORD
      - POSTGRES_DB
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  n8n:
    <<: [*common]
    image: docker.n8n.io/n8nio/n8n:latest
    ports:
      - "5678:5678"
    volumes:
      - ./n8n_data:/home/robot/.n8n
    environment:
      - DB_TYPE
      - DB_POSTGRESDB_HOST
      - DB_POSTGRESDB_USER
      - DB_POSTGRESDB_PASSWORD
      - N8N_DIAGNOSTICS_ENABLED
      - N8N_PERSONALIZATION_ENABLED
      - N8N_ENCRYPTION_KEY
      - N8N_USER_MANAGEMENT_JWT_SECRET
      - OLLAMA_HOST
    depends_on:
      - db

  test:
    <<: [*gpu]
    image: nvidia/cuda:12.8.1-base-ubuntu24.04
    command: nvidia-smi
